{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Useful imports",
   "id": "92f776b26d5df9e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from src.preprocessing import data_diabetes, preprocessing"
   ],
   "id": "e26750bcefc87e11"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Charging the csv in a dataframe\n",
    "\n",
    "First step is to take a look at the data to know what we are dealing with.\n",
    "\n",
    "We charge the csv in a panda dataframe and apply multiple methods to visualize the data.\n",
    "\n",
    "A quick search to the source of the data (https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset?select=diabetes_binary_health_indicators_BRFSS2015.csv) gives us the information on the meaning of the data and precisions on the features."
   ],
   "id": "15c785d5f9429ba1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(data_diabetes)\n",
    "df"
   ],
   "id": "111c4b209832072"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "253680 different patients and 22 features.\n",
    "\n",
    "Most of the features are binary : 1.0 if true and 0.0 if false.\n",
    "\n",
    "Couple exemples : \n",
    "- **\"Diabetes_binary** : if the patient has diabetes.\n",
    "- **\"Fruits\"** : if the patient eats at least one fruit a day.\n",
    "- **\"PhysHlth\"** : if the patient practiced a physical activity in the last 30 days.\n",
    "- **\"Smoker\"** : if the patient had more than 100 cigarettes (5 packs) in his life\n",
    "- **\"HighBP\"** : high blood pressure\n",
    "\n",
    "**\"Sex\"** is 0.0 for female and 1.0 for male\n",
    "\n",
    "Some features have numerical values :\n",
    "- **\"BMI\"** : Body Mass Index : weight(kg) / height(m)t^2 (18.5 to 24.9 is \"normal\", 25 to 29.9 is \"overweight\")\n",
    "- **\"MentHlth\"** : Days of poor mental health on a 1 to 30 days scale\n",
    "- **\"Age\"** : Using the 13-level age category -> 1 = 18-24 | 9 = 60-64 | 13 = 80 \n",
    "- **\"Education\"** : level of studies -> 0 = never attended school or only kindergarden etc...\n",
    "- **\"Income\"** : level of income on a 1 to 8 scale (in dollars) -> 1 = less than 10,000 | 5 = less than 35,000 | 8 = 75,000 or more"
   ],
   "id": "ba62445ba46c822c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info()",
   "id": "1118e0fe74635de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.describe()",
   "id": "4c0ecb2f1647c5d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For binary features, the mean acts as a computation of the percentage of the patients which validate it.\n",
    "\n",
    "A quick look at the means of the different binary features shows for exemple that most of the patients had a cholesterol check in the last 5 years (0.96), that around half of them smoke (0.44) and that around 14% of them has diabetes (0.139)"
   ],
   "id": "569f658b6cbc5a6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can print exactly the number of patient having diabetes :",
   "id": "3a7ef4f3e380b942"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[\"Diabetes_binary\"].value_counts()",
   "id": "e2677e4f00e675e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is interesting to see the correlation between features. Here we choose features that seems more relevant than others to determine if a patient has diabetes to keep the correlation matrix readable.",
   "id": "eac062a299597262"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "relevant_features = [\"HighBP\", \"HighChol\", \"BMI\", \"Sex\", \"Diabetes_binary\"]\n",
    "corr = df[relevant_features].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0)\n",
    "plt.show()"
   ],
   "id": "ca33f34c500cc35e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see the distribution of each feature on diabetics and no diabetics",
   "id": "9a1ce9b5db64ca55"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, axes = plt.subplots(7, 3, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "for idx, feature in enumerate(df.columns[1:]):\n",
    "    sns.kdeplot(\n",
    "        data=df, x=feature, hue=\"Diabetes_binary\", ax=axes[idx], fill=True, palette=\"Set2\", alpha=0.3, common_norm=False\n",
    "    )\n",
    "    axes[idx].grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b0f8b9e3ecf99843"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analysis",
   "id": "6507150e24fca423"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K nearest neighbour\n",
   "id": "cfda4fe12b98b4d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first algorithm we decide to use is the KNN algorithm as it is easy and quick to implement. ",
   "id": "9aa266b24acb1f1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.knn import KNNModel\n",
    "\n",
    "samples = preprocessing(data=data_diabetes, test_size=0.3, validation_size=0.1)\n",
    "model = KNNModel()\n",
    "model.train(x=samples.X_train, y=samples.y_train)\n",
    "model.benchmark(x=samples.X_test, y=samples.y_test)"
   ],
   "id": "5e22318737ff8dd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have the best results for K = 3.     \n",
    "At first sight, the results seem very good : for the non-diabetic people the precision is 88% and recall is 93%. \n",
    "However we see there is a problem when considering the diabic people : the precision is 37% and recall is 24%.  \n",
    "\n",
    "We decide to select only the features with an importance superior to 0.05 to see if it can improve the model and make it more interpretable."
   ],
   "id": "7f47d2d5823903c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "samples = preprocessing(data=data_diabetes, test_size=0.15, validation_size=0.15)\n",
    "\n",
    "cols = [0, 1, 3, 13, 18]\n",
    "samples.X_train = samples.X_train[:, cols]\n",
    "samples.X_test = samples.X_test[:, cols]\n",
    "samples.X_validation = samples.X_validation[:, cols]\n",
    "\n",
    "model = KNNModel()\n",
    "model.train(x=samples.X_train, y=samples.y_train)\n",
    "model.benchmark(x=samples.X_test, y=samples.y_test)"
   ],
   "id": "277e8e5020fdb00e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "There isn't any improvement in the model but the training and prediction is much faster. \n",
    "We can conclude that the diabete dataset is more complex than the spam dataset : we need a more complex algorithm than KNN.   "
   ],
   "id": "9387184d399bd428"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Neural network : MLP",
   "id": "b21e277456176434"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.nn_interface import MLPModel\n",
    "\n",
    "samples = preprocessing(data=data_diabetes, test_size=0.15, validation_size=0.15)\n",
    "model = MLPModel(input_size=21, epochs=15)\n",
    "model.train(samples)"
   ],
   "id": "47341334e34ee2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.benchmark(samples.X_test, samples.y_test)",
   "id": "6e997862da96ba6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We decide to use a MLP with 3 hidden layers to tackle this complex dataset as neural networks are very powerful.  \n",
    "We observe far better results than for KNN : precision for diabetic people is around 29% but recall is approx 83%. That means that the algorithm detects 83% of the diabetic cases which is a pretty good result. Indeed, eventhough the algorithm classifies non-diabetic people as diabetic people this doesn't have dramatic consequences. On the contrary, if diabetic people are classified as non-diabetic, it can have problematic consequences.\n",
    "That's why we prefer to have a high recall and a low precision for class 1 than a low recall and a high precision. \n",
    "Moreover the precision for diabetic people is very high (96%) and recall remains high (67%).  \n",
    "We can note that some features seem to have played a bigger role than others when predicting : GenHlth (36% of feature importance), BMI (20%) and age (18%).\n",
    "\n",
    "However if we compare with the spam dataset, the training is much longer because of the amount of data but the loss doesn't decrease that much : the MLP struggles to reach excellent performances, only 15 epochs are sufficient\n"
   ],
   "id": "c547630bceb0d80f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We decide to select only the 5 features that have an importance above 0.05 to train our model again and see if we have better results. ",
   "id": "9b3b5fc778e99d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "samples = preprocessing(data=data_diabetes, test_size=0.15, validation_size=0.15)\n",
    "\n",
    "cols = [0, 1, 3, 13, 18]\n",
    "samples.X_train = samples.X_train[:, cols]\n",
    "samples.X_test = samples.X_test[:, cols]\n",
    "samples.X_validation = samples.X_validation[:, cols]\n",
    "\n",
    "\n",
    "model = MLPModel(input_size=5, epochs=15)\n",
    "model.train(samples)"
   ],
   "id": "5abc1b989642c809"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.benchmark(samples.X_test, samples.y_test)",
   "id": "7ace313f174dd9f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We don't see any improvement in our model : we have the same results as before.",
   "id": "fc6d2fc2961f9823"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "9bf6ce8388003642"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.RForest import RForest\n",
    "\n",
    "samples = preprocessing(data=data_diabetes, test_size=0.3, validation_size=0.1)\n",
    "model = RForest()\n",
    "model.train(x=samples.X_train, y=samples.y_train)"
   ],
   "id": "599dd1e525fab236"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.benchmark(x=samples.X_test, y=samples.y_test)",
   "id": "6edd66c47f7ea367"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The Random Forest isn't effective at all to tackle this problem even when we optimize the hyperparameters by using a Grid Search. Recall for class 1 is around 15% which is even worse than for the KNN model...  \n",
    "However an interesting thing that we can notice is that the MLP and the Random Forest use some of the same features to predict the results  : BMI, GenHlth and age. The other important features are HighBP and HighChol. "
   ],
   "id": "7b256df0d3e0c954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once again we decide to select only the features with an importance superior to 0.05. This will able the model to be more efficient and maybe have better results as the GridSearch on Random Forest takes a lot of time. ",
   "id": "778275e69314e240"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "samples = preprocessing(data=data_diabetes, test_size=0.15, validation_size=0.15)\n",
    "\n",
    "cols = [0, 1, 3, 13, 18]\n",
    "samples.X_train = samples.X_train[:, cols]\n",
    "samples.X_test = samples.X_test[:, cols]\n",
    "samples.X_validation = samples.X_validation[:, cols]\n",
    "\n",
    "\n",
    "model = RForest()\n",
    "model.train(x=samples.X_train, y=samples.y_train)\n",
    "model.benchmark(x=samples.X_test, y=samples.y_test)"
   ],
   "id": "dfd17265b0cb5198"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model was way more faster to train with only these 5 features. However the results are not better than before : the recall is even worse than the previous model. ",
   "id": "2538be1fa41979ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear SVC",
   "id": "66a678859b711114"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.kernel_methods import LinearSVC_\n",
    "\n",
    "samples = preprocessing(data=data_diabetes, test_size=0.3, validation_size=0.1)\n",
    "model = LinearSVC_()\n",
    "model.train(x=samples.X_train, y=samples.y_train)"
   ],
   "id": "de82343c09b99c17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.benchmark(x=samples.X_test, y=samples.y_test)",
   "id": "91e4757f2e41cd3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To optimise the hyperparameters used by the LinearSVC model we use a Grid Search. \n",
    "The LinearSVC model we use here is almost as good as the MLP model we used above : we have a recall of 76.5% for class 1 while still having a precision of 85% and a recall of 72% for class 0.  \n",
    "We notice that this model uses less features than the others. However is has also important features in common (BMI, GenHlth, age) with the MLP and the KNN and it uses HighBP like RandomForest.  "
   ],
   "id": "d21c0562be090233"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We decide once again to select only the most important features to train our model once again. ",
   "id": "607f05c628355654"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "samples = preprocessing(data=data_diabetes, test_size=0.15, validation_size=0.15)\n",
    "\n",
    "cols = [0, 1, 2, 3, 10, 13, 18]\n",
    "samples.X_train = samples.X_train[:, cols]\n",
    "samples.X_test = samples.X_test[:, cols]\n",
    "samples.X_validation = samples.X_validation[:, cols]\n",
    "\n",
    "\n",
    "model = LinearSVC_()\n",
    "model.train(x=samples.X_train, y=samples.y_train)\n",
    "model.benchmark(x=samples.X_test, y=samples.y_test)"
   ],
   "id": "7f18e57e06aad65d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The feature selection doesn't improve the results either.",
   "id": "4527981ffd1e8cde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conclusion : ",
   "id": "88fd2f6c663171f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The model for diabetes being more complex than the model for spams, the KNN and Random Forest algorithms are not useful anymore.  \n",
    "The neural networks and LinearSVC, eventhough they are not perfect, achieve very good recall scores for class 1 (80% and 76%) while maintaining high precision and recall scores for class 0.  \n",
    "Thus, for this diabete problem, the neural network is the best model.   \n",
    "Note that we can increase the recall for class 1 by playing on the decision threshold (person is classified as diabetic when probability is above 0.3 for example). \n",
    "Moreover we decided to do some selection features to keep only the most important features : this doesn't improve the models but it makes the models clearer and more easily interpretable."
   ],
   "id": "8308f9969b549746"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
